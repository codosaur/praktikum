{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы (из проекта курса «Статистический анализ данных»). Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится — вы её уже сделали.\n",
    "\n",
    "Постройте модель с максимально большим значением *accuracy*. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до 0.75. Проверьте *accuracy* на тестовой выборке самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/users_behavior.csv')\n",
    "print(data.head())\n",
    "print()\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Файл открывается. В данных уверены: \"*Предобработка данных не понадобится — вы её уже сделали*\". Идем дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим исходные данные на обучающую, валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train 60 %\n",
      "data_valid 20 %\n",
      "data_test 20 %\n"
     ]
    }
   ],
   "source": [
    "# Данные делим на 3 группы в пропорции 3:1:1\n",
    "# для разделения данных на 3 группы дважды применим train_test_split \n",
    "data_train, data_valid1 = train_test_split(data, test_size=0.4, random_state=12345)\n",
    "data_valid, data_test = train_test_split(data_valid1, test_size=0.5, random_state=12345)\n",
    "print('data_train', round(100 * data_train.shape[0] / data.shape[0]), '%')\n",
    "print('data_valid', round(100 * data_valid.shape[0] / data.shape[0]), '%')\n",
    "print('data_test', round(100 * data_test.shape[0] / data.shape[0]), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Исследуйте модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее (до тестрования) работаем только с выборками data_train и data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = data_train.drop('is_ultra', axis=1)\n",
    "train_target = data_train['is_ultra']\n",
    "valid_features = data_valid.drop('is_ultra', axis=1)\n",
    "valid_target = data_valid['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для задачи классификации мы выучили 3 модели:\n",
    "* дерево решений\n",
    "* случайный лес\n",
    "* логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.762053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.754277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.727838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.713841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.713841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  accuracy\n",
       "1       11.0  0.762053\n",
       "0        1.0  0.754277\n",
       "2       21.0  0.727838\n",
       "3       31.0  0.713841\n",
       "4       41.0  0.713841"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# В таблице dtc_accuracy для каждого гиперпараметра max_depth будем хранить полученное значение accuracy\n",
    "dtc_accuracy = pd.DataFrame(columns=['max_depth', 'accuracy'])\n",
    "\n",
    "# Проверим качество модели для разных значений показатели max_depth (i)\n",
    "for i in range(1, 42, 10):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=i)\n",
    "    model.fit(train_features, train_target)\n",
    "    predictions = model.predict(valid_features)\n",
    "    accuracy = model.score(valid_features, valid_target)\n",
    "    dtc_accuracy.loc[dtc_accuracy.shape[0]] = [i, accuracy]\n",
    "\n",
    "dtc_accuracy.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее значение точности получено для гиперпараметра max_depth=11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели \"случайный лес\" у нас есть дополнительный параметр n_estimators. Создадим отдельную таблицу точности, в которой max_depth также будет меняться от 1 до 41 с шагом 10, и для каждого из значений max_depth гиперпараметр n_estimators также будет проходить от 1 до 41 с шагом 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.794712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.794712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>41.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.793157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.793157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.791602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  n_estimators  accuracy\n",
       "6        11.0          11.0  0.794712\n",
       "14       21.0          41.0  0.794712\n",
       "22       41.0          21.0  0.793157\n",
       "17       31.0          21.0  0.793157\n",
       "13       21.0          31.0  0.791602"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_accuracy = pd.DataFrame(columns=['max_depth', 'n_estimators', 'accuracy'])\n",
    "\n",
    "# Проверим качество модели для разных значений показатели max_depth (i) и n_estimators (j)\n",
    "for i in range(1, 42, 10):\n",
    "    for j in range(1, 42, 10):\n",
    "        model = RandomForestClassifier(random_state=12345, max_depth=i, n_estimators=j)\n",
    "        model.fit(train_features, train_target)\n",
    "        predictions = model.predict(valid_features)\n",
    "        accuracy = model.score(valid_features, valid_target)\n",
    "        rfc_accuracy.loc[rfc_accuracy.shape[0]] = [i, j, accuracy]\n",
    "\n",
    "rfc_accuracy.sort_values(by='accuracy', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность модели \"случайное дерево\" лучше, чем у единичного дерева. Максимальное значение точности предстаказаний было достигнуто для сочетания гиперпараметров max_depth=11, n_estimators=11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для логистической регрессии мы не будем подбирать какие-либо параметры. Просто получим accuracy и проверим, не произойдет ли какой-либо сенсации (например, логистическая регрессии по точности опередит случайный лес)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7589424572317263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=12345)\n",
    "model.fit(train_features, train_target)\n",
    "predictions = model.predict(valid_features)\n",
    "accuracy = model.score(valid_features, valid_target)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемо места по точности предсказаний распределились следующим образом:\n",
    "1. случайный лес\n",
    "2. решающее дерево\n",
    "3. логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В итоге для проверки на тестовой выборке выбираем модель \"случайный лес\" с гиперпараметрами max_depth=11, n_estimators=11**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проверьте модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7931570762052877\n"
     ]
    }
   ],
   "source": [
    "test_features = data_test.drop('is_ultra', axis=1)\n",
    "test_target = data_test['is_ultra']\n",
    "\n",
    "model = RandomForestClassifier(random_state=12345, max_depth=11, n_estimators=11)\n",
    "model.fit(train_features, train_target)\n",
    "predictions = model.predict(test_features)\n",
    "accuracy = model.score(test_features, test_target)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Требуемая точность (0,75) достигнута!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (бонус) Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под адекватностью мы понимаем то, что наша модель лучше случайности. Используем DummyClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6842923794712286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Проверим точность как если бы каждый раз мы выбирали самое популярное значений (в нашем случае это is_ultra=0)\n",
    "# Для этого установим гиперпараметр strategy='most_frequent'\n",
    "dummy_model = DummyClassifier(random_state=12345, strategy='most_frequent')\n",
    "dummy_model.fit(train_features, train_target)\n",
    "predictions = dummy_model.predict(test_features)\n",
    "accuracy = dummy_model.score(test_features, test_target)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также были опробованы другие стратегии для модели DummyClassifier, но получить точность более чем 0,68 не получилось. \n",
    "\n",
    "**Таким образом, мы делаем вывод, что наша выбранная модель \"случайный лес\" адекватно выбирает подходящий для клиента тариф.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Jupyter Notebook открыт\n",
    "- [ ] Весь код исполняется без ошибок\n",
    "- [ ] Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ] Выполнено задание 1: данные загружены и изучены\n",
    "- [ ] Выполнено задание 2: данные разбиты на три выборки\n",
    "- [ ] Выполнено задание 3: проведено исследование моделей\n",
    "    - [ ] Рассмотрено больше одной модели\n",
    "    - [ ] Рассмотрено хотя бы 3 значения гипепараметров для какой-нибудь модели\n",
    "    - [ ] Написаны выводы по результатам исследования\n",
    "- [ ] Выполнено задание 3: Проведено тестирование\n",
    "- [ ] Удалось достичь accuracy не меньше 0.75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
